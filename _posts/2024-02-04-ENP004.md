---
layout: post
title: 英语新闻004期
categories: ENP
description: 资料来源于Nature杂志
keywords: ENP,英语新闻
---

- **NEWS**
- 01 February 2024

# This AI learnt language by seeing the world through a baby’s eyes 这个人工智能通过婴儿的眼睛看世界来学习语言

**A neural network that taught itself to recognize objects using the filmed experiences of a single infant could offer new insights into how humans learn.**
一个神经网络可以利用一个婴儿的视频经验来自学识别物体，这可以为人类如何学习提供新的见解。

![](https://media.nature.com/lw767/magazine-assets/d41586-024-00288-1/d41586-024-00288-1_26685816.jpg?as=webp)

> The artificial intelligence learned using video and audio from a helmet-mounted camera worn by Sam — here aged 18 months
> 人工智能使用Sam佩戴的头盔摄像头的视频和音频进行学习-在这里18个月大。

An artificial intelligence (AI) model has learnt to recognize words such as ‘crib’ and ‘ball’, by studying headcam recordings of a tiny fraction of a single baby’s life.
一个人工智能（AI）模型已经学会了识别单词，如“婴儿床”和“球”，通过研究头部摄像头记录的一小部分婴儿的生活。

The results suggest that AI can help us to understand how humans learn, says Wai Keen Vong, co-author of the study and a researcher in AI at New York University. This has previously been unclear, because other language-learning models such as ChatGPT learn on billions of data points, which is not comparable to the real-world experiences of an infant, says Vong. “We don’t get given the internet when we’re born.”
研究结果表明，人工智能可以帮助我们理解人类是如何学习的，该研究的合着者、纽约大学人工智能研究员阿威·基恩·冯说。Vong说，这一点以前并不清楚，因为ChatGPT等其他语言学习模型需要数十亿个数据点来学习，这与婴儿的真实体验是不可比拟的。“我们一出生就没有互联网。

The authors hope that the research, reported in *Science* on 1 February[1](https://www.nature.com/articles/d41586-024-00288-1#ref-CR1), will feed into long-standing debates about how children learn language. The AI learnt only by building associations between the images and words it saw together; it was not programmed with any other prior knowledge about language. That challenges some cognitive-science theories that, to attach meaning to words, babies need some innate knowledge about how language works, says Vong.
作者希望这项在2月1日发表在《科学》杂志上的研究能够为关于儿童如何学习语言的长期争论提供素材。人工智能只能通过在一起看到的图像和单词之间建立联系来学习;它没有被编程任何其他关于语言的先验知识。Vong说，这挑战了一些认知科学理论，即婴儿需要一些关于语言如何运作的先天知识才能将意义赋予单词。

The study is “a fascinating approach” to understanding early language acquisition in children, says Heather Bortfeld, a cognitive scientist at the University of California, Merced.
默塞德市加州大学的认知科学家石楠·波特菲尔德说，这项研究是了解儿童早期语言习得的“一种迷人的方法”。

## Baby’s-eye view 婴儿视角

Vong and his colleagues used 61 hours of recordings from a camera mounted on a helmet worn by a baby boy named Sam, to gather experiences from the infant’s perspective. Sam, who lives near Adelaide in Australia, wore the camera for around one hour twice each week (roughly 1% of his waking hours), from the age of six months to around two years.
Vong和他的同事们使用了61小时的录像，录像来自一个安装在一个名叫Sam的男婴戴的头盔上的摄像机，从婴儿的角度收集经验。住在澳大利亚阿德莱德附近的山姆，从六个月大到两岁左右，每周两次戴着相机大约一个小时（大约占他清醒时间的1%）。

The researchers trained their neural network — an AI inspired by the structure of the brain — on frames from the video and words spoken to Sam, transcribed from the recording. The model was exposed to 250,000 words and corresponding images, captured during activities such as playing, reading and eating. The model used a technique called contrastive learning to learn which images and text tend to go together and which do not, to build up information that can used to predict which images certain words, such as ‘ball’ and ‘bowl’, refer to.
研究人员训练了他们的神经网络-一种受大脑结构启发的人工智能-从视频中的帧和对山姆说的话，从录音中转录下来。该模型暴露于250，000个单词和相应的图像，这些图像在玩耍，阅读和进食等活动中捕获。该模型使用了一种名为对比学习的技术来学习哪些图像和文本倾向于在一起，哪些不，以建立可用于预测某些单词（如“球”和“碗”）所指的图像的信息。

To test the AI, the researchers asked the model to match a word with one of four candidate images, a test that is also used to evaluate children’s language abilities. It successfully classified the object 62% of the time — much better than the 25% expected by chance, and comparable to a similar AI model that was trained on 400 million image–text pairs from outside this data set.
为了测试人工智能，研究人员要求模型将一个单词与四个候选图像中的一个进行匹配，这一测试也用于评估儿童的语言能力。它在62%的时间内成功地对对象进行了分类-比预期的25%要好得多，并且与在来自该数据集之外的4亿个图像-文本对上训练的类似AI模型相当。

For some words, such as ‘apple’ and ‘dog’, the model was able to correctly identify previously unseen examples — something humans generally find relatively easy. On average, it did so successfully 35% of the time. The AI was better at identifying objects out of context when they occurred frequently in the training data. It was also best at identifying objects that vary little in their appearance, says Vong. Words which can refer to a variety of different items — such as ‘toy’ — were harder to learn.
对于一些单词，比如“苹果”和“狗”，该模型能够正确识别以前看不见的例子--人类通常会发现这相对容易。平均而言，它成功地做到了35%的时间。当对象在训练数据中频繁出现时，AI更善于识别它们。Vong说，它也最擅长识别外观变化不大的物体。可以指代各种不同物品的单词--比如“玩具”--更难学。

## Lessons about learning 关于学习的课程

The study’s reliance on data from a single child might raise questions about the generalizability of its findings, because childrens’ experiences and environments vary greatly, says Bortfeld. But the exercise revealed that a lot can be learnt in the infant's earliest days through only forming associations between different sensory sources, she adds. The findings also challenge scientists — such as US linguist Noam Chomsky — who claim that language is too complex and the input of information is too sparse, for language acquisition to happen through general learning processes. “These are among the strongest data I’ve seen showing that such ‘special’ mechanisms are not necessary,” says Bortfeld.
波特菲尔德说，这项研究依赖于一个孩子的数据，这可能会引起人们对其研究结果的普遍性的质疑，因为孩子们的经历和环境差异很大。但她补充说，这项试验表明，在婴儿最早的日子里，只有通过在不同的感官来源之间形成联系，才能学到很多东西。这些发现也对美国语言学家诺姆·乔姆斯基（Noam Chomsky）等科学家提出了挑战，他们声称语言过于复杂，信息输入过于稀疏，语言习得不可能通过一般的学习过程进行。“这些是我见过的最有力的数据之一，表明这种'特殊'机制是不必要的，”Bortfeld说。

Real-world language learning is much richer and varied than the AI experienced. The researchers say that, because the AI is limited to training on still images and written text, it could not experience interactions that are inherent to a real baby’s life. The AI struggled to learn the word ‘hand’ for example, which is usually learnt early on in an infant’s life, says Vong. “Babies have their own hands, they have a lot of experience with them. That’s definitely a missing component of our model.”
现实世界的语言学习比人工智能经历的更丰富和多样。研究人员表示，由于人工智能仅限于对静态图像和书面文本进行训练，因此它无法体验到真实的婴儿生活所固有的互动。例如，人工智能很难学习“手”这个词，这通常是在婴儿生命的早期学习的，Vong说。“婴儿有自己的手，他们有很多经验。这绝对是我们模型中缺少的一个组成部分。“

“The potential for further refinements to make the model more aligned with the complexities of human learning is vast, offering exciting avenues for advancements in cognitive sciences,” says Anirudh Goyal, a machine learning scientist at the University of Montreal, Canada.
“进一步改进模型以使其更符合人类学习的复杂性的潜力是巨大的，为认知科学的进步提供了令人兴奋的途径，”加拿大蒙特利尔大学机器学习科学家Anirudh Goyal说。

<a target="_blank" style="border: 1px solid white;box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.3);border-radius: 2px 2px 2px 2px;font-size: 12px;line-height: 14px;position:fixed;z-index:999;display: inline-block;width: 25px;word-wrap: break-word;padding: 10px 6px;color: #FFFFFF; background: #0098FF; right: 0; bottom: 20px;" rel="noopener" href="https://jinshuju.net/f/IyliGU">反馈&投稿</a>